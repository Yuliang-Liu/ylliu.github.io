---
title: '从识别到认知：2023–2026 年文档智能的结构性转向'
date: 2026-2-24
permalink: /posts/2026/02/blog-post-1/
tags:
  - cool posts
  - category1
  - category2
---

## 从识别到认知：2023–2026 年文档智能的结构性转向思考

在数字经济与科技强国战略持续推进的背景下，文档智能早已不只是一个工程优化问题，而是国家基础能力建设的一部分。更为关键的是，海量文档本身正是大模型训练不可或缺的数据燃料——学术论文、技术标准、政府公报、法律判例、财务报告、医学记录与工业档案，共同构成了当代智能系统的知识源泉。没有结构化、可理解、可计算的文档数据，就不存在真正高质量的大模型能力。如何高效、可靠、规模化地解析与理解这些文档，不仅关系到知识治理与产业数字化水平，也直接影响人工智能底层模型的训练质量与国家创新体系的运行效率。文档智能因此不再是边缘技术，而成为支撑国家重大发展战略与大模型生态建设的关键基础设施。

<p align="center">
<img width="1000" height="450" alt="image" src="https://github.com/user-attachments/assets/ef238378-a45c-4696-8f91-9453b42f8db6" />
</p>

在过去二十年里，这一领域的核心问题被简化为一个相对明确的技术目标：如何更准确地识别字符。光学字符识别（OCR）系统围绕检测、识别与版面分析构建出高度模块化的流水线架构，并在工程上取得显著成功。字符错误率的持续下降，使文档数字化成为可能，也为信息检索和搜索引擎奠定了基础。然而，自 2023 年以来，我们正在见证一场更深层次的范式转移——文档理解不再被视为字符恢复问题，而被重新定义为结构建模与语义推理问题。

这一转向首先体现在端到端视觉—语言模型（VLM）的[兴起](https://github.com/Yuliang-Liu/AWESOME-OCR-LLM)。传统 OCR 流水线强调模块分解与误差隔离，但也不可避免地带来误差逐级传播与目标函数割裂的问题。相比之下，端到端 VLM 直接从文档图像生成结构化输出，例如 Markdown、JSON，甚至可执行代码，将版面结构、语义信息与逻辑关系纳入统一建模框架。这并非简单替代原有模块，而是在任务定义层面完成一次升级：优化目标从字符级准确率转向任务级可用性。

随着任务目标的变化，训练机制也随之演进。强化学习逐渐进入文档建模领域。文档真正的挑战并不在于单个字符是否正确，而在于整体结构是否自洽：标题层级是否稳定，跨页表格是否对齐，编号系统是否连续，引用关系是否闭合。这些问题属于全局结构优化，而非局部感知判断。通过引入可执行反馈——例如代码运行验证、公式计算校验或结构一致性检测——模型开始在训练阶段对“逻辑正确性”负责。文档理解因此从感知问题，过渡为带有决策性质的系统性问题。

更具颠覆性的趋势是 OCR-free 文档理解模型的出现。这类模型并不显式输出字符识别结果，而是在视觉 token 空间中直接建模语义与结构关系。文档被视为视觉—逻辑复合体，而非线性文本序列的容器。字符不再是唯一中间表示，结构本身成为关键载体。这种转变意味着，我们的目标不再是“还原文本”，而是“恢复可操作语义结构”。从信息恢复到语义执行，问题本质发生改变。

与此同时，scaling law的方式也在发生微妙变化。虽然大模型拓展了能力边界，但文档场景的现实需求推动了模型小型化趋势。参数规模低于 1B 的紧凑型文档 VLM，通过蒸馏、参数高效微调与任务专用优化，实现了在企业与政务环境中的可部署性。这标志着文档智能正在从研究驱动阶段走向产业落地阶段。模型不仅要强，还必须可控、可私有化、可持续运行。

对于长文档而言，挑战同样被重新界定。过去的讨论集中在上下文窗口长度，但实践表明，真正困难的是跨页一致性与状态管理。页码连续性、章节编号稳定性、跨页表格拼接与引用匹配，本质上是全局 token 一致性问题，而不仅仅是上下文容量问题。因此，长文档解析更像一种带有记忆机制的推理过程，需要多轮处理、状态更新与局部修复，而非一次性生成。这种认知正在重塑长文档系统的架构设计。

评估体系的变化进一步印证了范式转移。传统 CER 或 WER 无法反映结构错误带来的真实风险。新的评估方法更强调“可执行性”：JSON 是否可解析，代码是否可运行，数学结果是否正确，表格是否结构完整。这种可执行评估，将文档理解从表层匹配推进到功能验证层面，使“可用性”成为核心指标。

然而，生成式方法的普及也带来了新的风险结构。传统 OCR 的错误多为误识别或遗漏，其边界相对清晰。生成式 OCR 则可能产生语义连贯但事实上不存在的内容，即“幻觉”。风险因此从确定性偏差转向概率性偏差。问题不再是“识别错了什么”，而是“是否生成了不应存在的内容”。在法律、金融与医疗等高风险领域，这一风险转移尤为关键，也对系统的可信度设计提出更高要求。

在这些趋势交汇之处，一种更高层级的系统形态正在浮现：文档智能体（Document Agents）。这类系统的能力远超传统的解析器——它们不仅理解页面内容，还能在文档内部进行检索、规划、推理并调用外部工具来完成复杂任务。例如，类似 Manus 这样的自主 AI Agent 已经展示了跨文档、多步骤执行的能力，能够访问工具、操作文件系统并生成可交付成果，而不仅仅返回文本答案；这一类技术被视为从“回答问题”向“执行任务”的关键进展。与此同时，像 OpenClaw/OpenClawD 这样可自托管的 AI 助手生态，也在推动自动化工作流的落地，使得智能体可以在本地与外部服务之间无缝协同，执行包括文件操作、数据整理和日程安排等自动化任务。这样的智能体不仅可以跨页追踪变量、汇总财务指标、识别合同风险，还可以主动生成报告草稿、调度多阶段流程，从而将文档从静态信息载体转变为真正可交互、可编排、可自动化的知识环境。

这种能力的提升，对 AI4Science 的意义尤为突出。科学研究高度依赖论文、实验记录、技术报告与专利文献。科学知识的累积，本质上是文档的积累。若模型能够准确理解结构、执行公式、追踪变量与实验条件，那么文档智能将成为科研自动化与科学发现的重要驱动力。从文献综述自动化到跨论文知识整合，从实验步骤抽取到数值验证，文档理解能力直接决定 AI4Science 系统的上限。

<p align="center">
<img width="553" height="356" alt="image" src="https://github.com/user-attachments/assets/8601605f-a273-4a72-b671-c635736315b0" />
</p>

回顾 OCR 过去二十年的演进路径，我们从“识别文本字符”走到了“理解复杂文档结构”，技术形态经历了从规则驱动到深度学习，再到多模态大模型的跃迁。然而，技术能力的提升并未消解一个更根本的问题——真实世界的非结构化文档仍在持续爆发式增长。PDF、扫描件、科研手稿、课堂板书、企业内部报告、历史档案等海量资料，仍以结构松散、语义隐含的形式存在。如何将这些非结构化知识持续、稳定地转化为机器可计算、可推理、可验证的结构化资产，已成为决定文档智能长期价值的核心议题。

从更宏观的视角看，这不仅是 OCR 技术升级的问题，而是数据治理范式的重构。正如数据仓库之父 Bill Inmon 所强调的，将原始文档转化为可分析的数据形态，是构建高价值数据体系的前提；而 MIT 信息质量研究的代表性学者 Richard Wang 也指出，数据质量与数据治理能力直接决定数据驱动决策的可靠性。未来，文档智能不再只是“读懂页面”，而是成为连接非结构化知识与高质量数据资产之间的关键枢纽。

长期来看，文档智能的颠覆性潜力体现在两个层面：一是技术层面，从流程优化走向结构重建，从字符识别走向语义执行；二是战略层面，非结构化文档数据治理能力将直接影响国家知识体系的数字化深度与人工智能系统的持续进化能力。可以预见，谁能够率先建立稳定、高质量、可持续更新的非结构化文档治理体系，谁就将在知识智能化浪潮中占据主动。

文档，不再只是被存储和检索的信息载体，而将成为机器理解世界、参与决策与推动创新的重要基础设施。这或许是大模型时代下的OCR 更重要的历史使命。

刘禹良

2026/2/25
